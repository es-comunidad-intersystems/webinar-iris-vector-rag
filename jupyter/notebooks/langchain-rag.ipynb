{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b7564f-eed0-486c-b72d-6657ffc23a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.30.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting langchain-iris\n",
      "  Downloading langchain_iris-0.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.2.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-0.2.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai) (4.0.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.7.2-py3-none-any.whl.metadata (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Collecting sqlalchemy-iris>=0.14.0 (from langchain-iris)\n",
      "  Using cached sqlalchemy_iris-0.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.0.22)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.63-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (23.2)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.3 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading openai-1.30.4-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_iris-0.2.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached langchain-0.2.1-py3-none-any.whl (973 kB)\n",
      "Using cached tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached langchain_community-0.2.1-py3-none-any.whl (2.1 MB)\n",
      "Using cached langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
      "Using cached aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
      "Using cached langsmith-0.1.63-py3-none-any.whl (122 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Downloading pydantic-2.7.2-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "Using cached sqlalchemy_iris-0.14.0-py3-none-any.whl (141 kB)\n",
      "Using cached tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "Using cached marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "Using cached orjson-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tzdata, tenacity, regex, python-dotenv, pydantic-core, orjson, numpy, mypy-extensions, multidict, marshmallow, h11, frozenlist, distro, annotated-types, yarl, typing-inspect, tiktoken, sqlalchemy-iris, pydantic, pandas, httpcore, aiosignal, langsmith, httpx, dataclasses-json, aiohttp, openai, langchain-core, langchain-text-splitters, langchain, langchain-community, langchain-iris\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 dataclasses-json-0.6.6 distro-1.9.0 frozenlist-1.4.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain-0.2.1 langchain-community-0.2.1 langchain-core-0.2.1 langchain-iris-0.2.0 langchain-text-splitters-0.2.0 langsmith-0.1.63 marshmallow-3.21.2 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 openai-1.30.4 orjson-3.10.3 pandas-2.2.2 pydantic-2.7.2 pydantic-core-2.18.3 python-dotenv-1.0.1 regex-2024.5.15 sqlalchemy-iris-0.14.0 tenacity-8.3.0 tiktoken-0.7.0 typing-inspect-0.9.0 tzdata-2024.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "!pip install pandas python-dotenv openai langchain-iris langchain tiktoken langchain-community langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab1560e1-a9b3-4efb-92b2-262cb2e15e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OpenAI APIKEY from env\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv('/home/jovyan/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ea5c6e-ccab-4d10-a292-e98c0ad3b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# text loading and splitting\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# IRIS as vector store\n",
    "from langchain_iris import IRISVector\n",
    "\n",
    "# parse response from llm\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd304014-c592-424c-80b5-f78b6379996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional. LangChain LangSmith https://www.langchain.com/langsmith\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import traceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e884abb-7210-435e-9e34-8b171c3bebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 513, which is longer than the specified 400\n",
      "Created a chunk of size 602, which is longer than the specified 400\n",
      "Created a chunk of size 455, which is longer than the specified 400\n",
      "Created a chunk of size 1251, which is longer than the specified 400\n",
      "Created a chunk of size 525, which is longer than the specified 400\n",
      "Created a chunk of size 1053, which is longer than the specified 400\n",
      "Created a chunk of size 639, which is longer than the specified 400\n",
      "Created a chunk of size 836, which is longer than the specified 400\n",
      "Created a chunk of size 931, which is longer than the specified 400\n",
      "Created a chunk of size 598, which is longer than the specified 400\n",
      "Created a chunk of size 694, which is longer than the specified 400\n",
      "Created a chunk of size 712, which is longer than the specified 400\n",
      "Created a chunk of size 626, which is longer than the specified 400\n",
      "Created a chunk of size 2448, which is longer than the specified 400\n",
      "Created a chunk of size 889, which is longer than the specified 400\n",
      "Created a chunk of size 541, which is longer than the specified 400\n",
      "Created a chunk of size 834, which is longer than the specified 400\n",
      "Created a chunk of size 501, which is longer than the specified 400\n",
      "Created a chunk of size 1080, which is longer than the specified 400\n",
      "Created a chunk of size 1328, which is longer than the specified 400\n",
      "Created a chunk of size 1357, which is longer than the specified 400\n",
      "Created a chunk of size 542, which is longer than the specified 400\n",
      "Created a chunk of size 797, which is longer than the specified 400\n",
      "Created a chunk of size 467, which is longer than the specified 400\n",
      "Created a chunk of size 838, which is longer than the specified 400\n",
      "Created a chunk of size 691, which is longer than the specified 400\n",
      "Created a chunk of size 566, which is longer than the specified 400\n",
      "Created a chunk of size 743, which is longer than the specified 400\n",
      "Created a chunk of size 1203, which is longer than the specified 400\n",
      "Created a chunk of size 518, which is longer than the specified 400\n",
      "Created a chunk of size 1395, which is longer than the specified 400\n",
      "Created a chunk of size 482, which is longer than the specified 400\n",
      "Created a chunk of size 522, which is longer than the specified 400\n",
      "Created a chunk of size 462, which is longer than the specified 400\n",
      "Created a chunk of size 730, which is longer than the specified 400\n",
      "Created a chunk of size 1297, which is longer than the specified 400\n",
      "Created a chunk of size 593, which is longer than the specified 400\n",
      "Created a chunk of size 415, which is longer than the specified 400\n",
      "Created a chunk of size 736, which is longer than the specified 400\n",
      "Created a chunk of size 2805, which is longer than the specified 400\n",
      "Created a chunk of size 1407, which is longer than the specified 400\n",
      "Created a chunk of size 408, which is longer than the specified 400\n",
      "Created a chunk of size 738, which is longer than the specified 400\n",
      "Created a chunk of size 453, which is longer than the specified 400\n",
      "Created a chunk of size 711, which is longer than the specified 400\n",
      "Created a chunk of size 794, which is longer than the specified 400\n",
      "/opt/conda/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# open llm model\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "\n",
    "# load text & split in chunks\n",
    "loader = TextLoader(\"/app/data/wiki-es-cervantes.txt\", encoding='utf-8')\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=400, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# function to use to calculate vectors (embeddings) from text\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d8fcb0-cb5a-4af7-8b24-2bec9ddc36a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris://demo:demo@iris:1972/USER\n"
     ]
    }
   ],
   "source": [
    "# IRIS connection string\n",
    "username = 'demo'\n",
    "password = 'demo' \n",
    "hostname = 'iris'\n",
    "port = '1972' \n",
    "namespace = 'USER'\n",
    "CONNECTION_STRING = f\"iris://{username}:{password}@{hostname}:{port}/{namespace}\"\n",
    "print(CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7663a8-7bf0-4933-91b3-df4baf220296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents (vectors from splitted text)\n",
    "# this will create the collection\n",
    "COLLECTION_NAME = \"wikicervantes\"\n",
    "\n",
    "db = IRISVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=docs,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a4b09ae-2237-47f7-a6c4-b869af3e8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the following if you are connecting to an existing collection\n",
    "#db = IRISVector(\n",
    "#    embedding_function=embeddings,\n",
    "#    collection_name=COLLECTION_NAME,\n",
    "#    connection_string=CONNECTION_STRING,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e6301b-92aa-4a35-8c2b-d8101eabceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs in vector store: 86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of docs in vector store: {len(db.get()['ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179074ef-84a7-4406-936e-1664946f66e8",
   "metadata": {},
   "source": [
    "# Questions & Answers using documents as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224f9c51-747f-45e0-9f90-8c858d66e3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# create llm\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f53b2421-9ff8-455a-a0bc-df70dabc4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response schema to parse response afterwards\n",
    "rsp_schema = ResponseSchema(\n",
    "    name=\"rsp\",\n",
    "    description=\"response to question\",\n",
    "    type=\"string\"\n",
    ")\n",
    "\n",
    "# prompt response schema\n",
    "response_schemas = [rsp_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "687492ad-6c29-4890-a96f-948a917da3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\\\n",
    "You are a Co-Pilot history teacher that helps students to understand history lessons.\n",
    "Using the context, provide a comprensible and clear response that will help a student to study History.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Use the following context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Do not use any other information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b3fa93d-bb58-424d-a27f-e3eb0fc9da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=query_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88efc09f-cf08-4ade-8bb5-2652c30dd6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": QA_CHAIN_PROMPT\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33b25358-5bfe-4605-9838-a0dd84a37399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a Co-Pilot history teacher that helps students to understand history lessons.\n",
      "Using the context, provide a comprensible and clear response that will help a student to study History.\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"rsp\": string  // response to question\n",
      "}\n",
      "```\n",
      "\n",
      "Use the following context:\n",
      "Cervantes y la religión\n",
      "\n",
      "Cervantes es sumamente original. Parodiando un género que empezaba a periclitar, como el de los libros de caballerías, creó otro género sumamente vivaz, la novela polifónica, donde se superponen las cosmovisiones y los puntos de vista hasta confundirse en complejidad con la misma realidad, recurriendo incluso a juegos metaficcionales. En la época la épica podía escribirse también en prosa, y con el precedente en el teatro del poco respeto a los modelos clásicos de Lope de Vega, le cupo a él en suma fraguar la fórmula del realismo en la narrativa tal y como había sido preanunciada en España por toda una tradición literaria desde el Cantar del Mío Cid, ofreciéndosela a Europa, donde Cervantes tuvo más discípulos que en España. La novela realista entera del siglo XIX está marcada por este magisterio. Por otra parte, otra gran obra maestra de Cervantes, las Novelas ejemplares, demuestra la amplitud de miras de su espíritu y su deseo de experimentar con las estructuras narrativas. En esta colección de novelas el autor experimenta con la novela bizantina (La española inglesa), la novela policíaca o criminal (La fuerza de la sangre, El celoso extremeño), el diálogo lucianesco (El coloquio de los perros), la miscelánea de sentencias y donaires (El licenciado Vidriera), la novela picaresca (Rinconete y Cortadillo), la narración constituida sobre una anagnórisis (La gitanilla), etc.\n",
      "\n",
      "En un principio, la pretensión de Cervantes fue combatir el auge que habían alcanzado los libros de caballerías, satirizándolos con la historia de un hidalgo manchego que perdió la cordura por leerlos, creyéndose caballero andante. Para Cervantes, el estilo de las novelas de caballerías era pésimo, y las historias que contaba eran disparatadas. A pesar de ello, a medida que iba avanzando el propósito inicial fue superado, y llegó a construir una obra que reflejaba la sociedad de su tiempo y el comportamiento humano.\n",
      "\n",
      "Se ha conservado una providencia de Felipe II que data de 1569, donde manda prender a Miguel de Cervantes, acusado de herir en un duelo a un tal Antonio Sigura, maestro de obras. Si se tratara realmente de Cervantes y no de un homónimo, podría ser este el motivo que le hizo pasar a Italia. Llegó a Roma en diciembre del mismo año. Allí leyó los poemas caballerescos de Ludovico Ariosto, que tanto influirán en el Don Quijote según Marcelino Menéndez Pelayo, y los Diálogos de amor del judío sefardita León Hebreo (Yehuda Abrabanel), de inspiración neoplatónica, que determinarán su idea del amor. Cervantes se imbuye del estilo y del arte de Italia, y guardará siempre tan gratísimo recuerdo de aquellos estados, que al principio de El licenciado Vidriera, una de sus Novelas ejemplares, hace poco menos que una guía turística de ella:\n",
      "\n",
      "Es ampliamente considerado una de las máximas figuras de la literatura española. Fue el autor de El ingenioso hidalgo don Quijote de la Mancha, novela conocida habitualmente como El Quijote, que lo llevó a ser mundialmente conocido y a la cual muchos críticos han descrito como la primera novela moderna, así como una de las mejores obras de la literatura universal, cuya cantidad de ediciones y traducciones solo es superada por la Biblia.​ A Cervantes se le ha dado el apelativo de «Príncipe de los Ingenios».​\n",
      "\n",
      "Question:\n",
      "por qué fue Cervantes relevante ?\n",
      "\n",
      "Do not use any other information.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'por qué fue Cervantes relevante ?', 'result': '```json\\n{\\n\\t\"rsp\": \"Cervantes fue relevante por su originalidad al crear un nuevo género literario, la novela polifónica, que reflejaba la sociedad de su tiempo y el comportamiento humano. Su obra maestra, El Quijote, es considerada la primera novela moderna y una de las mejores obras de la literatura universal, lo que lo llevó a ser mundialmente conocido y a ser considerado una de las máximas figuras de la literatura española.\"\\n}\\n```', 'source_documents': [Document(page_content='Cervantes y la religión', metadata={'source': '/app/data/wiki-es-cervantes.txt'}), Document(page_content='Cervantes es sumamente original. Parodiando un género que empezaba a periclitar, como el de los libros de caballerías, creó otro género sumamente vivaz, la novela polifónica, donde se superponen las cosmovisiones y los puntos de vista hasta confundirse en complejidad con la misma realidad, recurriendo incluso a juegos metaficcionales. En la época la épica podía escribirse también en prosa, y con el precedente en el teatro del poco respeto a los modelos clásicos de Lope de Vega, le cupo a él en suma fraguar la fórmula del realismo en la narrativa tal y como había sido preanunciada en España por toda una tradición literaria desde el Cantar del Mío Cid, ofreciéndosela a Europa, donde Cervantes tuvo más discípulos que en España. La novela realista entera del siglo\\xa0XIX está marcada por este magisterio. Por otra parte, otra gran obra maestra de Cervantes, las Novelas ejemplares, demuestra la amplitud de miras de su espíritu y su deseo de experimentar con las estructuras narrativas. En esta colección de novelas el autor experimenta con la novela bizantina (La española inglesa), la novela policíaca o criminal (La fuerza de la sangre, El celoso extremeño), el diálogo lucianesco (El coloquio de los perros), la miscelánea de sentencias y donaires (El licenciado Vidriera), la novela picaresca (Rinconete y Cortadillo), la narración constituida sobre una anagnórisis (La gitanilla), etc.', metadata={'source': '/app/data/wiki-es-cervantes.txt'}), Document(page_content='En un principio, la pretensión de Cervantes fue combatir el auge que habían alcanzado los libros de caballerías, satirizándolos con la historia de un hidalgo manchego que perdió la cordura por leerlos, creyéndose caballero andante. Para Cervantes, el estilo de las novelas de caballerías era pésimo, y las historias que contaba eran disparatadas. A pesar de ello, a medida que iba avanzando el propósito inicial fue superado, y llegó a construir una obra que reflejaba la sociedad de su tiempo y el comportamiento humano.', metadata={'source': '/app/data/wiki-es-cervantes.txt'}), Document(page_content='Se ha conservado una providencia de Felipe II que data de 1569, donde manda prender a Miguel de Cervantes, acusado de herir en un duelo a un tal Antonio Sigura, maestro de obras. Si se tratara realmente de Cervantes y no de un homónimo, podría ser este el motivo que le hizo pasar a Italia. Llegó a Roma en diciembre del mismo año. Allí leyó los poemas caballerescos de Ludovico Ariosto, que tanto influirán en el Don Quijote según Marcelino Menéndez Pelayo, y los Diálogos de amor del judío sefardita León Hebreo (Yehuda Abrabanel), de inspiración neoplatónica, que determinarán su idea del amor. Cervantes se imbuye del estilo y del arte de Italia, y guardará siempre tan gratísimo recuerdo de aquellos estados, que al principio de El licenciado Vidriera, una de sus Novelas ejemplares, hace poco menos que una guía turística de ella:', metadata={'source': '/app/data/wiki-es-cervantes.txt'}), Document(page_content='Es ampliamente considerado una de las máximas figuras de la literatura española. Fue el autor de El ingenioso hidalgo don Quijote de la Mancha, novela conocida habitualmente como El Quijote, que lo llevó a ser mundialmente conocido y a la cual muchos críticos han descrito como la primera novela moderna, así como una de las mejores obras de la literatura universal, cuya cantidad de ediciones y traducciones solo es superada por la Biblia.\\u200b A Cervantes se le ha dado el apelativo de «Príncipe de los Ingenios».\\u200b', metadata={'source': '/app/data/wiki-es-cervantes.txt'})]}\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain(\"por qué fue Cervantes relevante ?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb3636d1-1126-4384-aa74-e800b7ef54a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rsp': 'Cervantes fue relevante por su originalidad al crear un nuevo género literario, la novela polifónica, que reflejaba la sociedad de su tiempo y el comportamiento humano. Su obra maestra, El Quijote, es considerada la primera novela moderna y una de las mejores obras de la literatura universal, lo que lo llevó a ser mundialmente conocido y a ser considerado una de las máximas figuras de la literatura española.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract actual response\n",
    "output_dict = output_parser.parse(result[\"result\"])\n",
    "output_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
