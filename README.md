En este repositorio encontrar√°s el c√≥digo y los ejemplos utilizados en el [Webinar - Base de datos Vectorial y Aplicaciones de IA Generativa](https://es.community.intersystems.com/post/nuevo-webinar-en-espa√±ol-base-de-datos-de-vectores-y-rag-aplicaciones-ia-generativa-sobre-tus).

# ¬øQu√© vas a aprender?
üìç Con este webinar y siguiendo los ejemplos paso a paso aprender√°s:

* Para qu√© sirve representar informaci√≥n como vectores y qu√© papel juegan las bases de datos vectoriales
* C√≥mo puedes crear aplicaciones RAG *(Retrieval Augmented Generation)* que utilicen LLMs ü§ñ (e.g. ChatGPT) que sean capaces de resolver cuestiones utilizando como fuente de informaci√≥n tus propios datos.


# ¬øQu√© necesitas?
* [Docker](https://www.docker.com/products/docker-desktop) - para ejecutar [InterSystems IRIS Community](https://www.intersystems.com/products/intersystems-iris/), la plataforma de datos que utilizaremos para almacenar informaci√≥n y ejecutar c√≥digo.
* _Opcionalmente_, cualquier cliente SQL como [DBeaver Community](https://dbeaver.io/download/) capaz de conectar por JDBC. En su defecto, lo podr√°s hacer por el propio portal web de IRIS.
* [Postman](https://www.postman.com/downloads/) - para lanzar peticiones REST.
* [API Key de OpenAI](https://platform.openai.com/api-keys) -  necesitar√°s utilizar servicios de OpenAI para la segunda parte de este webinar. Si no tienes a√∫n una API Key creada en OpenAI, cr√©ate una cuenta y en la secci√≥n "API Key" haz click en "Create new secret key". 

## Instalaci√≥n
1. Clona o descarga el repositorio desde GitHub
```shell
git clone https://github.com/es-comunidad-intersystems/webinar-iris-vector-rag
cd webinar-iris-vector-rag
```

2. Configura tu API key de OpenAI

Necesitar√°s utilizar servicios de OpenAI para la segunda parte de este webinar.

Crea un fichero `.env` en la raiz del directorio donde hayas clonado el repositorio con un contenido como este:
```
OPENAI_API_KEY="<your-api-key>"
```


2. Inicia la instancia [InterSystems IRIS Community](https://www.intersystems.com/products/intersystems-iris/)
```shell
docker compose up
```

‚ö†Ô∏è _¬°Importante!_ la construcci√≥n de la imagen tardar√° unos minutos porque tiene que descargar varias dependencias de librer√≠as Python üêç

3. Con la instancia en marcha, podr√°s acceder al [Mng. Portal](http://localhost:52773/csp/sys/UtilHome.csp)
* Usuario: `demo`
* Password: `demo`


# Base de Datos Vectorial

<img src="img/diagram-exercise-vectordb.png" width="1024" />

Para esta primera parte cargaremos un conjunto de datos sobre catas de vinos üçá originalmente disponible en [Kaggle](https://www.kaggle.com/datasets/zynicide/wine-reviews).

[Aqu√≠](./data) tenemos preparadas unas versiones de 500 y 5K registros para hacer pruebas.

Vamos a trabajar principalmente utilizando SQL y despu√©s a√±adiremos algunos m√©todos utilizando VSCode.

Puedes conectarte por SQL utilizando el [Explorador SQL](http://localhost:52773/csp/sys/exp/%25CSP.UI.Portal.SQL.Home.zen?$NAMESPACE=USER) del Portal o directamente utilizando cualquier herramienta como [DBeaver](https://dbeaver.io).

## Crear tabla
InterSystems IRIS nos permite almacenar vectores y utilizar operaciones para realizar b√∫squedas ([aqu√≠](https://docs.intersystems.com/iris20241/csp/docbook/Doc.View.cls?KEY=GSQL_vecsearch) ten√©is m√°s informaci√≥n.)

Como primer paso, crearemos una tabla directamente en SQL para cargar el conjunto de datos üçá y adem√°s a√±adiremos una columna que ser√° la encargada de almacenar el vector correspondiente a la descripci√≥n.

```sql
CREATE TABLE webinar_data.WineReviews (
        uid INT,                       
        country VARCHAR(255),
        description VARCHAR(2000),                 -- descripci√≥n en texto libre
        designation VARCHAR(255),
        points INT,
        price DOUBLE,
        province VARCHAR(255),
        region VARCHAR(255),
        variety VARCHAR(255),
        description_vector VECTOR(DOUBLE, 384)    -- vector correspondiente a la descripci√≥n
)
```

## Cargar datos de prueba

Cargamos a continuaci√≥n los CSV de prueba. Utilizamos la funcionalidad [LOAD DATA](https://docs.intersystems.com/iris20241/csp/docbook/Doc.View.cls?KEY=RSQL_loaddata) que directamente nos ahorra much√≠simo trabajo üôÇ 

```sql
LOAD DATA FROM FILE '/app/data/wine-reviews-5K.csv'
INTO webinar_data.WineReviews (uid,country,description,designation,points,price,province,region,variety)
VALUES (num,country,description,designation,points,price,province,region1,variety)
USING {"from":{"file":{"header":true, "charset": "UTF-8"}}}
```

Echemos un vistazo a los datos que se han cargado:

```sql
SELECT country, count(*) total
FROM webinar_data.WineReviews
GROUP BY country
ORDER BY count(*) DESC
```

## Calcular Vectores (encoding) para los datos de prueba

Como has podido ver, la columna "description_vector" est√° vac√≠a. No tenemos vectores calculados a√∫n.

Vamos a calcular vectores utilizando un modelo pre-entrenado llamado [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2). Este modelo calcular√° vectores de 384 dimensiones por cada descripci√≥n que le pasemos.

Llamaremos a este modelo a trav√©s de Python embebido en IRIS.

En VS Code:
* Conecta con la instancia de IRIS
* Localiza la clase `webinar.data.WineReviews` en el servidor.
* Esta clase se corresponde con la definici√≥n que acabamos de hacer en SQL. InterSystems IRIS mantiene autom√°ticamente la correspondencia entre clases / objetos y tablas SQL.
* Click dereecho y "Exportar". As√≠ podr√°s editar la clase en tu VSCode.

A√±ade a continuaci√≥n el siguiente m√©todo y compila la clase. Cuando llames a este m√©todo, actualizar√° cada fila de `webinar.data.WineReviews` con el vector calculado correspondiente a la descripci√≥n en la columna `description_vector` utilizando el modelo all-MiniLM-L6-v2.

```objectscript
ClassMethod AddEncodings() [ Language = python ]
{
    import iris
    import pandas
    from sentence_transformers import SentenceTransformer

    rs = iris.sql.exec("SELECT uid, description FROM webinar_data.WineReviews")
    df = rs.dataframe()
    
    # Load a pre-trained sentence transformer model. This model's output vectors are of size 384
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    # Generate embeddings for all descriptions at once. Batch processing makes it faster
    embeddings = model.encode(df['description'].tolist(), normalize_embeddings=True)

    # Add the embeddings to the DataFrame
    df['description_vector'] = embeddings.tolist()

    stmt = iris.sql.prepare("UPDATE webinar_data.WineReviews SET description_vector = TO_VECTOR(?) where uid = ?")
    for index, row in df.iterrows():
        rs = stmt.execute(str(row['description_vector']), row['uid'])
}
```

Llama al m√©todo que acabas de a√±adir a la clase desde una sesi√≥n interactiva con IRIS en el [WebTerminal](http://localhost:52773/terminal/). La ejecuci√≥n del m√©todo tardar√° unos minutos:

```objectscript
do ##class(webinar.data.WineReviews).AddEncodings()
```

Despu√©s de ejecutar el m√©todo, vuelve a echar un vistazo a tus datos. ¬øYa tienes la columna `description_vector` rellena?


## A√±adir m√©todo para obtener encodings 

Hemos a√±adido los encodings (vectores) de la columna `description` en la columna `description_vector`. Necesitaremos adem√°s una manera de calcular el encoding correspondiente a cualquier cadena que queramos.

A√±ade en `webinar.data.WineReviews` el siguiente m√©todo. Este m√©todo podremos invocarlo directamente desde SQL como un procedimiento.

```objectscript
ClassMethod GetEncoding(sentence As %String) As %String [ Language = python, SqlProc ]
{
    import sentence_transformers
    # create the model and form the embeddings
    model = sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(sentence, normalize_embeddings=True).tolist() # Convert search phrase into a vector
    # convert the embeddings to a string
    return str(embeddings)
}
```

A continuaci√≥n puedes probar el m√©todo directamente desde SQL:

```sql
SELECT webinar_data.WineReviews_GetEncoding('blackberry')
```

## Realizar b√∫squedas de vectores similares

IRIS incorpora dos operaciones [VECTOR_DOT_PRODUCT](https://docs.intersystems.com/iris20241/csp/docbook/Doc.View.cls?KEY=RSQL_vectordotproduct) y [VECTOR_COSINE](https://docs.intersystems.com/iris20241/csp/docbook/Doc.View.cls?KEY=RSQL_vectorcosine) que podemos utilizar para buscar vectores similares.

Los vectores similares en el espacio vectorial del encoding, tendr√°n significados parecidos.

Podemos buscar directamente en SQL y combinar la b√∫squeda con cualquier otro criterio que nos queramos:

```sql
SELECT TOP 5 uid, country, designation, region, variety, description FROM webinar_data.WineReviews 
WHERE country in ('Spain', 'France') 
ORDER BY VECTOR_DOT_PRODUCT(description_vector, TO_VECTOR(webinar_data.WineReviews_GetEncoding('blackberry'))) DESC
```

## Servicio REST que utiliza b√∫squeda de vectores

En [WineReviewService.cls](./src/webinar/api/WineReviewService.cls) tienes un servicio REST que puedes compilar directamente y podr√°s probar en IRIS.

El servicio recibe una descripci√≥n y realiza una b√∫squeda de descripciones similares (vectores) en la tabla con la que has trabajado.

En [webinar.postman_collection.json](./webinar.postman_collection.json) tienes un proyecto Postman con peticiones configuradas para probarlo.

<img src="img/rest-wineservice.png" width="600" />

# Aplicaci√≥n IA Generativa sobre tus datos

Seguro que conoces m√∫ltiples ejemplos de **LLM (Large Language Models)** como **ChatGPT** (GPT-3.5, GPT-4), **BERT**, **Llama**, etc. Estos modelos se caracterizan entre otras cosas por manejar muy bien lenguajes naturales para comunicarse y por cierta capacidad de "razonamiento" para resolver cuestiones.

Estos LLMs son capaces de recibir **prompts** o instrucciones en forma de lenguaje natural que describe la tarea que una IA debe realizar, por ejemplo:

```
Clasifica el siguiente texto el neutral, positivo o negativo.
Texto: las vacaciones han estado bien.
```

Los modelos LLMs se han entrenado sobre conjuntos enormes de datos y son capaces de responder cuestiones utilizando como base la informaci√≥n de su entrenamiento.

Ser√≠a realmente interesante crear aplicaciones sobre nuestros propios datos y que puedan utilizar las capacidades de las LLMs para comprender lenguaje natural y razonar. A esta forma de hacer aplicaciones se la conoce como **RAG (Retrieval Augmented Generation)**.

<img src="img/rag-diagram-es.png" width="1024" />

Para construir aplicaciones RAG con nuestros propios datos necesitamos procesar la informaci√≥n en 2 fases:
* Carga de documentos - cargar nuestros datos, calculando los *embeddings** (vectores) correspondientes y almacenar en una base de datos vectorial.
* Procesar una *query* o consulta del usuario
  * Buscar en la base de datos vectorial los documentos relacionados con esa consulta. Con esos documentos, construimos el "contexto" para resolver la consulta.
  * Combinar la consulta del usuario y el contexto calculado previamente.
  * Lanzar la consulta a una LLM indicando que la resuelva utilizando el contexto que facilitamos.
  * Analizar la respuesta e integrar con el resto de nuestra aplicaci√≥n.

Vamos a implementar un ejemplo que sea capaz de responder a preguntas sobre un documento. En este caso utilizaremos una versi√≥n en [texto](data/wiki-es-cervantes.txt) del art√≠culo de la [Wikipedia](https://es.wikipedia.org/wiki/Miguel_de_Cervantes) sobre Miguel de Cervantes.

<img src="img/diagram-exercise-rag.png" width="1024" />

## ¬øQu√© vas a utilizar?
* InterSystems IRIS - Plataforma de datos que utilizar√°s como base de datos vectorial y tambi√©n para implementar un servicio REST que explote tu aplicaci√≥n RAG

* [LangChain](https://www.langchain.com/) - framework que simplifica la creaci√≥n de aplicaciones utilizando diferentes LLMs como OpenAI. Lo tenemos disponible para Python.

* OpenAI - LLM que utilizar√°s en el ejemplo.

* Jupyter - sistema de *notebooks* o cuadernos que nos permiten ejecutar Python de forma interactiva, normalmente se utiliza para exploraci√≥n de datos, pruebas, experimentos, etc.

## Prueba en Jupyter

En primer lugar utilizar√°s un cuaderno Jupyter para probar el concepto de aplicaci√≥n RAG.
* En http://localhost:8888/lab podr√°s acceder a Jupyter.
* Abre el notebook [langchain-rag.ipynb](./jupyter/notebooks/langchain-rag.ipynb)

Si sigues las instrucciones del cuaderno podr√°s ver:
* Instalaci√≥n de librer√≠as Python que necesitar√°s, incluido LangChain.
* Carga de documento (recuerda que us√°bamos el art√≠culo de Cervantes de la Wikpedia) en InterSystems IRIS como vectores
* Implementaci√≥n de un peque√±a aplicaci√≥n con LangChain y OpenAI que te permitir√° hacer preguntas sobre el documento que hemos cargado.

## Implementaci√≥n como servicio REST en IRIS

Despu√©s de probar c√≥mo funciona el concepto en Jupyter, tienes un ejemplo de un servicio REST sencillo en IRIS que recoge preguntas de usuarios sobre el documento y env√≠a las respuestas.

Aqu√≠ tienes el [c√≥digo](./src/webinar/api/CervantesService.cls). Comp√≠lalo en InterSystems IRIS desde VS Code.

En el proyecto [Postman](./webinar.postman_collection.json) tienes una petici√≥n preparada para poder para probarlo.

<img src="img/rest-cervantesservice.png" width="800"/>

# ¬øC√≥mo evolucionar sistemas para aprovechar estas caracter√≠sticas?

En la pr√°ctica, hoy en d√≠a muchas aplicaciones modernas tienen que solventar cosas como:
* Lidiar con diferentes fuentes de datos: APIs, sistemas _legacy_, diversas bases de datos, etc.
* Ser capaces de ofrecer una visi√≥n unificada, normalizada y de calidad de la informaci√≥n adaptada a los diferentes consumos que se va a hacer de ella por distintos perfiles, usuarios o casos de uso (e.g. an√°lisis, modelos de predicci√≥n IA, retro-alimentar sistemas operacionales, etc.)

<img src="img/iris-plataforma-datos.png" width="1024" />

Contar con una plataforma de datos como [InterSystems IRIS](https://www.intersystems.com/es/productos/intersystems-iris/) simplifica muchos de estos retos permitiendo una gesti√≥n sencilla de la __persistencia en diferentes modelos__ (¬°vectores incluidos!), __interoperabilidad__ con otras aplicaciones y __an√°lisis__ para gobernar la informaci√≥n y adaptarla a cada perfil de consumo que se requiera.

P√°sate por la [Comunidad de Desarrolladores](https://community.intersystems.com) üßëüèª‚Äçüíª y echa un vistazo.
